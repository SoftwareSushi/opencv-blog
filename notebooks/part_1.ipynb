{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Header\n",
        "import base64\n",
        "import requests\n",
        "import urllib.request\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "image_url = \"https://raw.githubusercontent.com/SoftwareSushi/marketing-resources/main/images/logo.png\"\n",
        "with urllib.request.urlopen(image_url) as response:\n",
        "    image_data = response.read()\n",
        "    encoded_image = base64.b64encode(image_data).decode()\n",
        "\n",
        "def load_html_from_github(raw_url):\n",
        "    response = requests.get(raw_url)\n",
        "    html_content = response.text\n",
        "    updated_html = html_content.replace('../images/logo.png', f\"data:image/png;base64, {encoded_image}\")\n",
        "    display(HTML(updated_html))\n",
        "\n",
        "load_html_from_github('https://raw.githubusercontent.com/SoftwareSushi/marketing-resources/refs/heads/main/html/cta-banner-with-logo.html')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fundamentals of Image Manipulation with OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenCV is the most common library for utilizing computer vision. In this first, we will be covering the foundational image manipulation techniques found within OpenCV that will both enable basic image manipulation, as well as serve as components of more advanced techniques that will be covered in later blogs within this series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports & Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4WKUfD1V9L8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adPC1sCoX_N5"
      },
      "outputs": [],
      "source": [
        "# Collecting the sample image\n",
        "image_url = \"https://raw.githubusercontent.com/SoftwareSushi/marketing-resources/main/images/Windows%20XP%20Background.jpg\"\n",
        "resp = urllib.request.urlopen(image_url)\n",
        "image_bytes = np.asarray(bytearray(resp.read()), dtype=np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIQolDUhX_Lm"
      },
      "outputs": [],
      "source": [
        "def create_mpl_figure(w,h,images):\n",
        "    plt.figure(figsize=[w,h])\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(1,len(images),i+1); plt.imshow(image); plt.title(f'Image {i+1}'); plt.axis('off');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List of Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Draw rectangle\n",
        "* Draw circle\n",
        "* Draw text\n",
        "* Resizing\n",
        "* Translation\n",
        "* Rotation\n",
        "* Horizontal Flipping\n",
        "* Vertical Flipping\n",
        "* Cropping\n",
        "* Zooming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this blog, we will be covering a variety of basic image manipulation techniques, all of which have a number of very useful implementations. Whether it be using rectangels, circles, resizing or cropping in order to track objects in images or videos, or using a combination of cropping, rotation, flipping in order to train a machine learning model to better recognize a given subject, each of these techniques has a variety of different real world applications which makes them useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drawing on Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What it does:** Adds visual elements (shapes and text) to an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why it matters:** Drawing on images is useful for annotation, visualization, or debugging during processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The Code & Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the sample image\n",
        "bgr_image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Color conversion to ensure proper display of images\n",
        "image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
        "image_edit = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Image Transformations\n",
        "cv2.line(image_edit, (50, 50), (200, 50), (0, 255, 0), 2)\n",
        "cv2.rectangle(image_edit, (50, 100), (200, 200), (255, 0, 0), 3)\n",
        "cv2.circle(image_edit, (150, 300), 40, (0, 0, 255), -1)\n",
        "cv2.putText(image_edit, \"OpenCV\", (50, 350), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "# Creation of the MatPlotLib figure for comparison of images\n",
        "create_mpl_figure(30,10, [image, image_edit])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What it does:** Resizing scales an image according to desired size of an image, scale factors fx and fy, and an interpolation method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why it matters:** Resizing, and more broadly image scaling as a whole can be very useful when it comes to image processing in the process of training a machine learning model. By reducing the number of pixels in an image, it can reduce the amount of time spent training for a given model by presenting it with less complex, albeit less accurate training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The Code & Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the sample image\n",
        "bgr_image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Color conversion to ensure proper display of images\n",
        "image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Getting the dimensions of the image\n",
        "height, width = image.shape[:2]\n",
        "\n",
        "# Creating the resized image\n",
        "resized_image = cv2.resize(image, (0,0), fx=0.1, fy=0.1, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "# Creation of the MatPlotLib figure for comparison of images\n",
        "create_mpl_figure(30,10, [image, resized_image])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What it does:** Shifts a given image by a specified number of pixels along the x and y axes. These pixel shifts can be represented by the following notations: tx & ty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why it matters:** Image translations are often used for object tracking, image alignment, and augmentation of data used for machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The Code & Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the sample image\n",
        "bgr_image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Color conversion to ensure proper display of images\n",
        "image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Image Translation\n",
        "# Getting the dimensions of the image\n",
        "height, width = image.shape[:2]\n",
        "\n",
        "# Create translation values\n",
        "tx, ty = width / 4, height / 4\n",
        "\n",
        "# Create translation matrix\n",
        "translation_matrix = np.array([\n",
        "    [1, 0, tx],\n",
        "    [0, 1, ty]\n",
        "], dtype=np.float32)\n",
        "\n",
        "# Apply matrix to image\n",
        "translated_image = cv2.warpAffine(src=image, M=translation_matrix, dsize=(width, height))\n",
        "\n",
        "# Creation of the MatPlotLib figure for comparison of images\n",
        "create_mpl_figure(30,10, [image, translated_image])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What it does:** Allows users to rotate a given image about a certain point in the image by a specified number of degrees using a rotation matrix, or by the center of the image in 90 degree increments by using the getRotationMatrix2D() & warpAffine() methods or the rotate() method accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why it matters:** Rotation can be used to automate rotation of important physical documents submitted electronically, increasing accuracy of other methods for recognizing text and images on scanned / photographically captured documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The Code & Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the sample image\n",
        "bgr_image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Color conversion to ensure proper display of images\n",
        "image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Specific Degree Rotation\n",
        "# Getting the dimensions of the image and the centerpoint\n",
        "height, width = image.shape[:2]\n",
        "center = (width/2, height/2)\n",
        "\n",
        "# Creating rotation matrix and applying it to the image, retaining the same dimensions\n",
        "rotate_matrix = cv2.getRotationMatrix2D(center=center, angle=45, scale=1)\n",
        "rotated_image = cv2.warpAffine(src=image, M=rotate_matrix, dsize=(width, height))\n",
        "\n",
        "# 90-Degree Increment Rotation\n",
        "rotated_image_2 = cv2.rotate(image, cv2.ROTATE_180) # Also try ROTATE_90_CLOCKWISE, ROTATE_90_COUNTERCLOCKWISE\n",
        "\n",
        "# Creation of the MatPlotLib figure for comparison of images\n",
        "create_mpl_figure(30,10, [image, rotated_image, rotated_image_2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Flipping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What it does:** Flips a given image about either the x axis, the y axis, or the x and y axis using the according flip codes 0, 1, and -1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why it matters:** Flipping images can create more reliable machine learning models by providing them with new data samples of existing data on which they have been trained. It can be also used to correct orientation of camera feeds for surveillance purposes, among many other uses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The Code & Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the sample image\n",
        "bgr_image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Color conversion to ensure proper display of images\n",
        "image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Flipping the sample image\n",
        "flipped_image = cv2.flip(image, -1)\n",
        "\n",
        "# Creation of the MatPlotLib figure for comparison of images\n",
        "create_mpl_figure(30,10, [image, flipped_image])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cropping / Zooming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What it does:** Displays a certain section of an image, defined by slicing a given image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why it matters:** Cropping can be very useful for object detection and recognition as a pre-processing step by cropping out the relevant portion of an image, allowing faster and more accurate recognition. Additionally, it can be used as a step of image of segmentation, and other techniques for image analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The Code & Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the sample image\n",
        "bgr_image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Color conversion to ensure proper display of images\n",
        "image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Get image shape (width = 550, height = 880, channel = 3)\n",
        "print(image.shape)\n",
        "\n",
        "# Crop image (image[row,column])\n",
        "cropped_image = image[50:180, 100:300]\n",
        "\n",
        "# Creation of the MatPlotLib figure for comparison of images\n",
        "create_mpl_figure(30,10, [image, cropped_image])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Pyramids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What it does:** Image Pyramids upsample or downsample a given image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why it matters:** Upsampling can be used to make smaller images more visible by making them larger, allowing them to be more accurately processed while increasing their size, whereas downsampling can decrease image sizes, enabling more images to be stored, as well as increasing the performance of image processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The Code & Output**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reading the sample image\n",
        "bgr_image = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "# Color conversion to ensure proper display of images\n",
        "image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Upscaling and downscaling the image\n",
        "upscaled_image = cv2.pyrUp(image)\n",
        "downscaled_image = cv2.pyrDown(image)\n",
        "\n",
        "# Creation of the MatPlotLib figure for comparison of images\n",
        "create_mpl_figure(30,10, [downscaled_image, image, upscaled_image])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "TkgFiWYTWDlq",
        "outputId": "79da1bea-f94e-4418-8579-a83a00079baf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<html>\n",
              "<head>\n",
              "    <style>\n",
              "        body { font-family: 'Arial', sans-serif; text-align: center; background-color: #061445; margin: 0; padding: 80px 20px; }\n",
              "        h1 { color: #fff; margin-bottom: 40px; font-size: 36px; font-weight: 600; line-height: 1.3; max-width: 1500px; margin-left: auto; margin-right: auto; }\n",
              "\n",
              "        .cta-container {\n",
              "            display: flex;\n",
              "            justify-content: center;\n",
              "            flex-wrap: wrap;\n",
              "            gap: 20px;\n",
              "            margin-top: 80px;\n",
              "        }\n",
              "\n",
              "        .cta {\n",
              "            display: inline-block;\n",
              "            font-size: 22px;\n",
              "            font-weight: bold;\n",
              "            color: #2a84dc;\n",
              "            background-color: #ffffff;\n",
              "            padding: 20px 50px;\n",
              "            border-radius: 50px;\n",
              "            text-decoration: none;\n",
              "            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);\n",
              "            transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);\n",
              "            position: relative;\n",
              "            overflow: hidden;\n",
              "            z-index: 1;\n",
              "        }\n",
              "\n",
              "        .cta:before {\n",
              "            content: '';\n",
              "            position: absolute;\n",
              "            top: 0;\n",
              "            left: -100%;\n",
              "            width: 100%;\n",
              "            height: 100%;\n",
              "            background: linear-gradient(90deg, rgba(255,255,255,0.1) 0%, rgba(255,255,255,0.3) 50%, rgba(255,255,255,0) 100%);\n",
              "            transition: all 0.4s ease;\n",
              "            z-index: -1;\n",
              "        }\n",
              "\n",
              "        .cta:hover {\n",
              "            background-color: #0f57a1;\n",
              "            color: #ffffff;\n",
              "            transform: translateY(-5px);\n",
              "            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);\n",
              "        }\n",
              "\n",
              "        .cta:hover:before {\n",
              "            left: 100%;\n",
              "        }\n",
              "\n",
              "        .cta:active {\n",
              "            transform: translateY(0px);\n",
              "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\n",
              "            transition: all 0.1s;\n",
              "        }\n",
              "\n",
              "        .cta-website:hover {\n",
              "            background-color: #127ae2;\n",
              "        }\n",
              "\n",
              "        .cta-call:hover {\n",
              "            background-color: #0c7c59;\n",
              "        }\n",
              "\n",
              "        .sub-text {\n",
              "            color: #fff;\n",
              "            font-size: 18px;\n",
              "            margin-top: 40px;\n",
              "            font-style: italic;\n",
              "        }\n",
              "\n",
              "        .social-proof {\n",
              "            color: #a9c2e8;\n",
              "            font-size: 18px;\n",
              "            margin-top: 40px;\n",
              "            font-style: italic;\n",
              "        }\n",
              "    </style>\n",
              "</head>\n",
              "\n",
              "<body>\n",
              "\n",
              "<h1>Take the first step towards actionable, data-driven growth today.</h1>\n",
              "\n",
              "<div class=\"cta-container\">\n",
              "    <a href=\"https://softwaresushi.com/\" target=\"_blank\" class=\"cta cta-website\">Explore Our Services ➔</a>\n",
              "    <a href=\"https://calendly.com/softwaresushi/quick-chat\" target=\"_blank\" class=\"cta cta-call\">Book a Free Consultation ➔</a>\n",
              "</div>\n",
              "\n",
              "<p class=\"social-proof\">5-star satisfaction from every client engagement.</p>\n",
              "\n",
              "</body>\n",
              "</html>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title Footer\n",
        "load_html_from_github('https://raw.githubusercontent.com/SoftwareSushi/marketing-resources/refs/heads/main/html/cta-banner.html')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
